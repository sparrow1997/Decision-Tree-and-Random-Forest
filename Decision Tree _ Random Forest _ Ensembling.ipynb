{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)\n",
    "print(iris.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if the dataset is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].value_counts()\n",
    "# Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will try to implement DTree with -\n",
    "#### 1. Entropy\n",
    "#### 2. Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x=df[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=df['species']  # Labels\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "\n",
    "x = scaler.transform(x)\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********InformationGain-Entropy as Split Measure******** \n",
      "\n",
      "Look at the importance of the included features\n",
      "petal width (cm)     0.924084\n",
      "petal length (cm)    0.046673\n",
      "sepal length (cm)    0.029243\n",
      "sepal width (cm)     0.000000\n",
      "dtype: float64\n",
      "Training  Accuracy\n",
      "0.9904761904761905\n",
      "Cross validation Accuracy Mean - \n",
      "0.9533333333333334\n",
      "Cross validation Standard Deviation - \n",
      "0.03399346342395189\n",
      "Test Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4, min_samples_split =2)\n",
    "dtree.fit(x_train, y_train)\n",
    "print(\"********InformationGain-Entropy as Split Measure******** \\n\");\n",
    "print(\"Look at the importance of the included features\")\n",
    "feature_imp_en = pd.Series(dtree.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\n",
    "print(feature_imp_en)\n",
    "print(\"Training  Accuracy\")\n",
    "print(dtree.score(x_train, y_train))\n",
    "\n",
    "cross_val_acc = model_selection.cross_val_score(dtree,x,y,cv=5, scoring =\"accuracy\")\n",
    "print(\"Cross validation Accuracy Mean - \")\n",
    "print(cross_val_acc.mean())\n",
    "\n",
    "print(\"Cross validation Standard Deviation - \")\n",
    "print(cross_val_acc.std())\n",
    "\n",
    "y_pred=dtree.predict(x_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the split that Entropy helped in creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"445pt\" height=\"552pt\"\r\n",
       " viewBox=\"0.00 0.00 444.50 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-548 440.5,-548 440.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#fcfffd\" stroke=\"black\" d=\"M289,-544C289,-544 135,-544 135,-544 129,-544 123,-538 123,-532 123,-532 123,-473 123,-473 123,-467 129,-461 135,-461 135,-461 289,-461 289,-461 295,-461 301,-467 301,-473 301,-473 301,-532 301,-532 301,-538 295,-544 289,-544\"/>\r\n",
       "<text text-anchor=\"start\" x=\"131\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) â‰¤ &#45;0.743</text>\r\n",
       "<text text-anchor=\"start\" x=\"162\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.585</text>\r\n",
       "<text text-anchor=\"start\" x=\"164.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 105</text>\r\n",
       "<text text-anchor=\"start\" x=\"151.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35, 36, 34]</text>\r\n",
       "<text text-anchor=\"start\" x=\"156.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M179.5,-417.5C179.5,-417.5 82.5,-417.5 82.5,-417.5 76.5,-417.5 70.5,-411.5 70.5,-405.5 70.5,-405.5 70.5,-361.5 70.5,-361.5 70.5,-355.5 76.5,-349.5 82.5,-349.5 82.5,-349.5 179.5,-349.5 179.5,-349.5 185.5,-349.5 191.5,-355.5 191.5,-361.5 191.5,-361.5 191.5,-405.5 191.5,-405.5 191.5,-411.5 185.5,-417.5 179.5,-417.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"89\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"87.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\r\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35, 0, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"85\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M183.897,-460.907C176.105,-449.652 167.636,-437.418 159.804,-426.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"162.532,-423.897 153.962,-417.667 156.776,-427.881 162.532,-423.897\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"149.49\" y=\"-438.564\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#f4fef8\" stroke=\"black\" d=\"M364.5,-425C364.5,-425 221.5,-425 221.5,-425 215.5,-425 209.5,-419 209.5,-413 209.5,-413 209.5,-354 209.5,-354 209.5,-348 215.5,-342 221.5,-342 221.5,-342 364.5,-342 364.5,-342 370.5,-342 376.5,-348 376.5,-354 376.5,-354 376.5,-413 376.5,-413 376.5,-419 370.5,-425 364.5,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"217.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) â‰¤ 0.725</text>\r\n",
       "<text text-anchor=\"start\" x=\"243\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.999</text>\r\n",
       "<text text-anchor=\"start\" x=\"249.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 70</text>\r\n",
       "<text text-anchor=\"start\" x=\"236.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 34]</text>\r\n",
       "<text text-anchor=\"start\" x=\"237.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M240.103,-460.907C246.26,-452.014 252.84,-442.509 259.194,-433.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.133,-435.235 264.947,-425.021 256.377,-431.251 262.133,-435.235\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"269.419\" y=\"-445.918\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#4fe88f\" stroke=\"black\" d=\"M285.5,-306C285.5,-306 136.5,-306 136.5,-306 130.5,-306 124.5,-300 124.5,-294 124.5,-294 124.5,-235 124.5,-235 124.5,-229 130.5,-223 136.5,-223 136.5,-223 285.5,-223 285.5,-223 291.5,-223 297.5,-229 297.5,-235 297.5,-235 297.5,-294 297.5,-294 297.5,-300 291.5,-306 285.5,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) â‰¤ 0.905</text>\r\n",
       "<text text-anchor=\"start\" x=\"161\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.469</text>\r\n",
       "<text text-anchor=\"start\" x=\"167.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40</text>\r\n",
       "<text text-anchor=\"start\" x=\"158.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 4]</text>\r\n",
       "<text text-anchor=\"start\" x=\"155.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M264.551,-341.907C258.317,-333.014 251.656,-323.509 245.223,-314.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"248.005,-312.201 239.399,-306.021 242.272,-316.219 248.005,-312.201\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M424.5,-298.5C424.5,-298.5 327.5,-298.5 327.5,-298.5 321.5,-298.5 315.5,-292.5 315.5,-286.5 315.5,-286.5 315.5,-242.5 315.5,-242.5 315.5,-236.5 321.5,-230.5 327.5,-230.5 327.5,-230.5 424.5,-230.5 424.5,-230.5 430.5,-230.5 436.5,-236.5 436.5,-242.5 436.5,-242.5 436.5,-286.5 436.5,-286.5 436.5,-292.5 430.5,-298.5 424.5,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"334\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"332.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\r\n",
       "<text text-anchor=\"start\" x=\"323.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 30]</text>\r\n",
       "<text text-anchor=\"start\" x=\"326\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>2&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M321.796,-341.907C329.781,-330.652 338.46,-318.418 346.484,-307.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"349.54,-308.848 352.471,-298.667 343.831,-304.798 349.54,-308.848\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#44e688\" stroke=\"black\" d=\"M207,-187C207,-187 49,-187 49,-187 43,-187 37,-181 37,-175 37,-175 37,-116 37,-116 37,-110 43,-104 49,-104 49,-104 207,-104 207,-104 213,-104 219,-110 219,-116 219,-116 219,-175 219,-175 219,-181 213,-187 207,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"45\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) â‰¤ &#45;1.082</text>\r\n",
       "<text text-anchor=\"start\" x=\"78\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.297</text>\r\n",
       "<text text-anchor=\"start\" x=\"84.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\r\n",
       "<text text-anchor=\"start\" x=\"75.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 2]</text>\r\n",
       "<text text-anchor=\"start\" x=\"72.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.204,-222.907C175.894,-214.014 169.152,-204.509 162.641,-195.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.386,-193.152 156.746,-187.021 159.677,-197.202 165.386,-193.152\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M341,-179.5C341,-179.5 249,-179.5 249,-179.5 243,-179.5 237,-173.5 237,-167.5 237,-167.5 237,-123.5 237,-123.5 237,-117.5 243,-111.5 249,-111.5 249,-111.5 341,-111.5 341,-111.5 347,-111.5 353,-117.5 353,-123.5 353,-123.5 353,-167.5 353,-167.5 353,-173.5 347,-179.5 341,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"253\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"255.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"start\" x=\"246.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\r\n",
       "<text text-anchor=\"start\" x=\"245\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>3&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M240.143,-222.907C248.224,-211.652 257.007,-199.418 265.129,-188.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"268.199,-189.831 271.188,-179.667 262.513,-185.749 268.199,-189.831\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M104,-68C104,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 104,-0 104,-0 110,-0 116,-6 116,-12 116,-12 116,-56 116,-56 116,-62 110,-68 104,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"16\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"18.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"9.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M101.935,-103.726C96.3371,-94.9703 90.413,-85.7032 84.7886,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.6226,-74.8399 79.2874,-68.2996 81.7247,-78.6103 87.6226,-74.8399\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#3ee684\" stroke=\"black\" d=\"M249.5,-68C249.5,-68 146.5,-68 146.5,-68 140.5,-68 134.5,-62 134.5,-56 134.5,-56 134.5,-12 134.5,-12 134.5,-6 140.5,-0 146.5,-0 146.5,-0 249.5,-0 249.5,-0 255.5,-0 261.5,-6 261.5,-12 261.5,-12 261.5,-56 261.5,-56 261.5,-62 255.5,-68 249.5,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"148\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.179</text>\r\n",
       "<text text-anchor=\"start\" x=\"154.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 37</text>\r\n",
       "<text text-anchor=\"start\" x=\"145.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"142.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.065,-103.726C159.663,-94.9703 165.587,-85.7032 171.211,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.275,-78.6103 176.713,-68.2996 168.377,-74.8399 174.275,-78.6103\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1b12e4d6910>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "from sklearn import tree\n",
    "dot_data = tree.export_graphviz(dtree, out_file=None, \n",
    "                      feature_names=iris.feature_names,  \n",
    "                      class_names=iris.target_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Ginni Index as Split Measure******** \n",
      "\n",
      "Look at the importance of the included features\n",
      "petal length (cm)    0.564710\n",
      "petal width (cm)     0.408193\n",
      "sepal length (cm)    0.027097\n",
      "sepal width (cm)     0.000000\n",
      "dtype: float64\n",
      "Training  Accuracy\n",
      "0.9904761904761905\n",
      "cross validation Accuracy Mean and standard deviation\n",
      "0.9600000000000002 0.03265986323710903\n",
      "Test Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "GTree=DecisionTreeClassifier(max_depth = 4, min_samples_split=2)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "GTree.fit(x_train,y_train)\n",
    "\n",
    "print(\"********Ginni Index as Split Measure******** \\n\");\n",
    "print(\"Look at the importance of the included features\")\n",
    "feature_imp_gi = pd.Series(GTree.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\n",
    "print(feature_imp_gi)\n",
    "\n",
    "print(\"Training  Accuracy\")\n",
    "print(GTree.score(x_train, y_train))\n",
    "\n",
    "Cross_Val_Accuracy = model_selection.cross_val_score(GTree, x, \n",
    "                                            y, cv=5,\n",
    "                                            scoring='accuracy')\n",
    "\n",
    "print(\"cross validation Accuracy Mean and standard deviation\")\n",
    "print(Cross_Val_Accuracy.mean(), Cross_Val_Accuracy.std())\n",
    "\n",
    "\n",
    "y_pred=GTree.predict(x_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"445pt\" height=\"552pt\"\r\n",
       " viewBox=\"0.00 0.00 444.50 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-548 440.5,-548 440.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#fcfffd\" stroke=\"black\" d=\"M286,-544C286,-544 138,-544 138,-544 132,-544 126,-538 126,-532 126,-532 126,-473 126,-473 126,-467 132,-461 138,-461 138,-461 286,-461 286,-461 292,-461 298,-467 298,-473 298,-473 298,-532 298,-532 298,-538 292,-544 286,-544\"/>\r\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) â‰¤ &#45;0.591</text>\r\n",
       "<text text-anchor=\"start\" x=\"174.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.666</text>\r\n",
       "<text text-anchor=\"start\" x=\"164.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 105</text>\r\n",
       "<text text-anchor=\"start\" x=\"151.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35, 36, 34]</text>\r\n",
       "<text text-anchor=\"start\" x=\"156.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M179.5,-417.5C179.5,-417.5 82.5,-417.5 82.5,-417.5 76.5,-417.5 70.5,-411.5 70.5,-405.5 70.5,-405.5 70.5,-361.5 70.5,-361.5 70.5,-355.5 76.5,-349.5 82.5,-349.5 82.5,-349.5 179.5,-349.5 179.5,-349.5 185.5,-349.5 191.5,-355.5 191.5,-361.5 191.5,-361.5 191.5,-405.5 191.5,-405.5 191.5,-411.5 185.5,-417.5 179.5,-417.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"102\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"87.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\r\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35, 0, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"85\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M183.897,-460.907C176.105,-449.652 167.636,-437.418 159.804,-426.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"162.532,-423.897 153.962,-417.667 156.776,-427.881 162.532,-423.897\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"149.49\" y=\"-438.564\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#f4fef8\" stroke=\"black\" d=\"M364.5,-425C364.5,-425 221.5,-425 221.5,-425 215.5,-425 209.5,-419 209.5,-413 209.5,-413 209.5,-354 209.5,-354 209.5,-348 215.5,-342 221.5,-342 221.5,-342 364.5,-342 364.5,-342 370.5,-342 376.5,-348 376.5,-354 376.5,-354 376.5,-413 376.5,-413 376.5,-419 370.5,-425 364.5,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"217.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) â‰¤ 0.725</text>\r\n",
       "<text text-anchor=\"start\" x=\"264\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"249.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 70</text>\r\n",
       "<text text-anchor=\"start\" x=\"236.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 34]</text>\r\n",
       "<text text-anchor=\"start\" x=\"237.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M240.103,-460.907C246.26,-452.014 252.84,-442.509 259.194,-433.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.133,-435.235 264.947,-425.021 256.377,-431.251 262.133,-435.235\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"269.419\" y=\"-445.918\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#4fe88f\" stroke=\"black\" d=\"M285.5,-306C285.5,-306 136.5,-306 136.5,-306 130.5,-306 124.5,-300 124.5,-294 124.5,-294 124.5,-235 124.5,-235 124.5,-229 130.5,-223 136.5,-223 136.5,-223 285.5,-223 285.5,-223 291.5,-223 297.5,-229 297.5,-235 297.5,-235 297.5,-294 297.5,-294 297.5,-300 291.5,-306 285.5,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) â‰¤ 0.905</text>\r\n",
       "<text text-anchor=\"start\" x=\"177.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\r\n",
       "<text text-anchor=\"start\" x=\"167.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40</text>\r\n",
       "<text text-anchor=\"start\" x=\"158.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 4]</text>\r\n",
       "<text text-anchor=\"start\" x=\"155.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M264.551,-341.907C258.317,-333.014 251.656,-323.509 245.223,-314.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"248.005,-312.201 239.399,-306.021 242.272,-316.219 248.005,-312.201\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M424.5,-298.5C424.5,-298.5 327.5,-298.5 327.5,-298.5 321.5,-298.5 315.5,-292.5 315.5,-286.5 315.5,-286.5 315.5,-242.5 315.5,-242.5 315.5,-236.5 321.5,-230.5 327.5,-230.5 327.5,-230.5 424.5,-230.5 424.5,-230.5 430.5,-230.5 436.5,-236.5 436.5,-242.5 436.5,-242.5 436.5,-286.5 436.5,-286.5 436.5,-292.5 430.5,-298.5 424.5,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"347\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"332.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\r\n",
       "<text text-anchor=\"start\" x=\"323.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 30]</text>\r\n",
       "<text text-anchor=\"start\" x=\"326\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>2&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M321.796,-341.907C329.781,-330.652 338.46,-318.418 346.484,-307.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"349.54,-308.848 352.471,-298.667 343.831,-304.798 349.54,-308.848\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#44e688\" stroke=\"black\" d=\"M207,-187C207,-187 49,-187 49,-187 43,-187 37,-181 37,-175 37,-175 37,-116 37,-116 37,-110 43,-104 49,-104 49,-104 207,-104 207,-104 213,-104 219,-110 219,-116 219,-116 219,-175 219,-175 219,-181 213,-187 207,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"45\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) â‰¤ &#45;1.082</text>\r\n",
       "<text text-anchor=\"start\" x=\"99\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.1</text>\r\n",
       "<text text-anchor=\"start\" x=\"84.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\r\n",
       "<text text-anchor=\"start\" x=\"75.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 2]</text>\r\n",
       "<text text-anchor=\"start\" x=\"72.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.204,-222.907C175.894,-214.014 169.152,-204.509 162.641,-195.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.386,-193.152 156.746,-187.021 159.677,-197.202 165.386,-193.152\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M341,-179.5C341,-179.5 249,-179.5 249,-179.5 243,-179.5 237,-173.5 237,-167.5 237,-167.5 237,-123.5 237,-123.5 237,-117.5 243,-111.5 249,-111.5 249,-111.5 341,-111.5 341,-111.5 347,-111.5 353,-117.5 353,-123.5 353,-123.5 353,-167.5 353,-167.5 353,-173.5 347,-179.5 341,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"266\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"255.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"start\" x=\"246.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\r\n",
       "<text text-anchor=\"start\" x=\"245\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>3&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M240.143,-222.907C248.224,-211.652 257.007,-199.418 265.129,-188.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"268.199,-189.831 271.188,-179.667 262.513,-185.749 268.199,-189.831\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M104,-68C104,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 104,-0 104,-0 110,-0 116,-6 116,-12 116,-12 116,-56 116,-56 116,-62 110,-68 104,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"29\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"18.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"9.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M101.935,-103.726C96.3371,-94.9703 90.413,-85.7032 84.7886,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.6226,-74.8399 79.2874,-68.2996 81.7247,-78.6103 87.6226,-74.8399\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#3ee684\" stroke=\"black\" d=\"M249.5,-68C249.5,-68 146.5,-68 146.5,-68 140.5,-68 134.5,-62 134.5,-56 134.5,-56 134.5,-12 134.5,-12 134.5,-6 140.5,-0 146.5,-0 146.5,-0 249.5,-0 249.5,-0 255.5,-0 261.5,-6 261.5,-12 261.5,-12 261.5,-56 261.5,-56 261.5,-62 255.5,-68 249.5,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"160.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.053</text>\r\n",
       "<text text-anchor=\"start\" x=\"154.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 37</text>\r\n",
       "<text text-anchor=\"start\" x=\"145.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"142.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.065,-103.726C159.663,-94.9703 165.587,-85.7032 171.211,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.275,-78.6103 176.713,-68.2996 168.377,-74.8399 174.275,-78.6103\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1b12e1b5400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(GTree, out_file=None, \n",
    "                      feature_names=iris.feature_names,  \n",
    "                      class_names=iris.target_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copmaring the importance given to each feature in Gini INdex and Entropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(feature_imp_en,feature_imp_en.index,'o--', color='red')\n",
    "# plt.step(feature_imp_en,feature_imp_en.index)\n",
    "plt.plot(feature_imp_gi,feature_imp_en.index,'o--', color='green')\n",
    "\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend(['Entropy', 'Gini-Index'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth of Tree vs Accuracy | Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height=1, accuracy=66.67%\n",
      "height=2, accuracy=93.33%\n",
      "height=3, accuracy=96.00%\n",
      "height=4, accuracy=95.33%\n",
      "height=5, accuracy=95.33%\n",
      "Height=3 highest accuracy which can be achieved at this height is 96.00% (Cross Validation)\n"
     ]
    }
   ],
   "source": [
    "# initialize the values of height for our desicion tree classifier along with the\n",
    "# list of accuracies for each value of depth\n",
    "depth = range(1, 6)\n",
    "acc = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    model = DecisionTreeClassifier(criterion=\"entropy\",max_depth = i, min_samples_split=2)\n",
    "    Cross_Val_Accuracy = model_selection.cross_val_score(model, x, \n",
    "                                            y, cv=5,\n",
    "                                            scoring='accuracy')\n",
    "    print(\"height=%d, accuracy=%.2f%%\" % (i, Cross_Val_Accuracy.mean() * 100))\n",
    "    acc.append(Cross_Val_Accuracy.mean())\n",
    "    \n",
    "#find the value of depth that has the largest accuracy\n",
    "i = int(np.argmax(acc))\n",
    "print(\"Height=%d highest accuracy which can be achieved at this height is %.2f%% (Cross Validation)\" % (depth[i],\n",
    "    acc[i] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth of Tree vs Accuracy | Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height=1, accuracy=66.67%\n",
      "height=2, accuracy=93.33%\n",
      "height=3, accuracy=97.33%\n",
      "height=4, accuracy=95.33%\n",
      "height=5, accuracy=96.00%\n",
      "Height=3 highest accuracy which can be achieved at this height is 97.33% (Cross Validation)\n"
     ]
    }
   ],
   "source": [
    "# initialize the values of height for our desicion tree classifier along with the\n",
    "# list of accuracies for each value of depth\n",
    "depth = range(1, 6)\n",
    "acc = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    model = DecisionTreeClassifier(max_depth = i, min_samples_split=2)\n",
    "    Cross_Val_Accuracy = model_selection.cross_val_score(model, x, \n",
    "                                            y, cv=5,\n",
    "                                            scoring='accuracy')\n",
    "    print(\"height=%d, accuracy=%.2f%%\" % (i, Cross_Val_Accuracy.mean() * 100))\n",
    "    acc.append(Cross_Val_Accuracy.mean())\n",
    "    \n",
    "#find the value of depth that has the largest accuracy\n",
    "i = int(np.argmax(acc))\n",
    "print(\"Height=%d highest accuracy which can be achieved at this height is %.2f%% (Cross Validation)\" % (depth[i],\n",
    "    acc[i] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traininng the complete model finally and the tuning the Hyperparameters\n",
    "#### Note: The accuracy was max at height = 3, hence before tuning the depth using GridSearchCV, the above mentioned value will be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 13  1]\n",
      " [ 0  1 15]]\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.93      0.93      0.93        14\n",
      "           2       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Final  Accuracy\n",
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Final Model \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "model = DecisionTreeClassifier(max_depth = 3, min_samples_split=2)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Final  Accuracy\")\n",
    "print(model.score(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 4}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.676 (+/-0.038) for {'criterion': 'gini', 'max_depth': 1}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 2}\n",
      "0.943 (+/-0.093) for {'criterion': 'gini', 'max_depth': 3}\n",
      "0.962 (+/-0.071) for {'criterion': 'gini', 'max_depth': 4}\n",
      "0.943 (+/-0.111) for {'criterion': 'gini', 'max_depth': 5}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10}\n",
      "0.943 (+/-0.111) for {'criterion': 'gini', 'max_depth': 11}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12}\n",
      "0.943 (+/-0.071) for {'criterion': 'gini', 'max_depth': 13}\n",
      "0.943 (+/-0.071) for {'criterion': 'gini', 'max_depth': 14}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15}\n",
      "0.943 (+/-0.071) for {'criterion': 'gini', 'max_depth': 16}\n",
      "0.943 (+/-0.111) for {'criterion': 'gini', 'max_depth': 17}\n",
      "0.933 (+/-0.097) for {'criterion': 'gini', 'max_depth': 20}\n",
      "0.676 (+/-0.038) for {'criterion': 'entropy', 'max_depth': 1}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 3}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 5}\n",
      "0.952 (+/-0.060) for {'criterion': 'entropy', 'max_depth': 6}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 8}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 9}\n",
      "0.952 (+/-0.060) for {'criterion': 'entropy', 'max_depth': 10}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 11}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 12}\n",
      "0.952 (+/-0.060) for {'criterion': 'entropy', 'max_depth': 13}\n",
      "0.943 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 14}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 15}\n",
      "0.943 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 16}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 17}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 20}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = DecisionTreeClassifier(min_samples_split=2)\n",
    "tuned_parameters = [{'max_depth': [1,2,3,4,5,6,8,9,10,11,12,13,14,15,16,17,20], 'criterion':['gini','entropy']}]\n",
    "clf = GridSearchCV(model, tuned_parameters, cv=5)\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "\n",
    "\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 12  2]\n",
      " [ 0  1 15]]\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.92      0.86      0.89        14\n",
      "           2       0.88      0.94      0.91        16\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best parametric values found above\n",
    "# criterion =  Gini, depth =4\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "model = DecisionTreeClassifier(criterion=\"gini\",max_depth = 4, min_samples_split=2)\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembling Techniques\n",
    "#### 1. Random Forest\n",
    "#### 2. Bagging Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 250}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 400}\n",
      "0.943 (+/-0.093) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100}\n",
      "0.943 (+/-0.093) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 150}\n",
      "0.943 (+/-0.093) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 100}\n",
      "0.943 (+/-0.093) for {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 250}\n",
      "0.943 (+/-0.093) for {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 300}\n",
      "0.943 (+/-0.093) for {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 350}\n",
      "0.943 (+/-0.093) for {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 12, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 13, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 13, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 13, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 13, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 13, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 13, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 13, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 13, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 14, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 14, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 14, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 14, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 14, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 14, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 14, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 14, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 400}\n",
      "0.829 (+/-0.230) for {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 50}\n",
      "0.886 (+/-0.177) for {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 100}\n",
      "0.857 (+/-0.200) for {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 150}\n",
      "0.829 (+/-0.230) for {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 200}\n",
      "0.857 (+/-0.200) for {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 250}\n",
      "0.857 (+/-0.200) for {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 300}\n",
      "0.857 (+/-0.200) for {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 350}\n",
      "0.857 (+/-0.200) for {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 400}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 200}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 11, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 11, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 11, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 11, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 11, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 11, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 11, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 11, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 12, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 12, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 12, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 12, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 12, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 12, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 12, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 12, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 13, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 13, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 13, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 13, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 13, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 13, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 13, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 13, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 14, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 14, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 14, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 14, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 14, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 14, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 14, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 14, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 16, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 17, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 17, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 17, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 17, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 17, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 17, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 17, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 17, 'n_estimators': 400}\n",
      "0.962 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 50}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 150}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 200}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 250}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 300}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 350}\n",
      "0.952 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 400}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_features='auto', min_samples_split=2,n_estimators = 20, random_state = 1)\n",
    "tuned_parameters = [{'max_depth': [1,2,3,4,5,6,8,9,10,11,12,13,14,15,16,17,20], 'criterion':['gini','entropy'],\n",
    "                    'n_estimators' : [50, 100, 150, 200, 250, 300, 350, 400]}]\n",
    "clf = GridSearchCV(model, tuned_parameters, cv=5)\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "\n",
    "\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score - \n",
      "0.9555555555555556\n",
      "[[15  0  0]\n",
      " [ 0 13  1]\n",
      " [ 0  1 15]]\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.93      0.93      0.93        14\n",
      "           2       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best parametric values found above\n",
    "# criterion =  Entropy, depth =3, n_estimators = 250\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "model = RandomForestClassifier(criterion=\"entropy\",max_depth = 3, min_samples_split=2,n_estimators = 250)\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print (\"Accuracy Score - \")\n",
    "print(model.score(x_test, y_test))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Randomized Trees\n",
    "\n",
    "\n",
    "In extremely randomized trees (see ExtraTreesClassifier and ExtraTreesRegressor classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9047619  0.9047619  0.95238095 1.         1.        ]\n",
      "0.9555555555555556\n",
      "OverFitted Model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "clf = ExtraTreesClassifier(criterion=\"entropy\",max_depth = 4, min_samples_split=2, random_state = 1)\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "print(scores)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.score(x_test, y_test))\n",
    "\n",
    "if (clf.score(x_test, y_test)-scores.mean()):\n",
    "    print(\"OverFitted Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling- Hard Voting\n",
    "\n",
    "### In order to predict the class labels based on the predicted class-probabilities (scikit-learn estimators in the VotingClassifier must support predict_proba method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.04) [Logistic Regression]\n",
      "Accuracy: 0.95 (+/- 0.04) [Random Forest]\n",
      "Accuracy: 0.96 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.96 (+/- 0.04) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50,max_depth=4, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "#eclf.fit(X_train, y_train)\n",
    "#print(\"Final  Accuracy\")\n",
    "#print(eclf.score(X, y))\n",
    "\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "# Here comes a scenario where the training data's feature engineering would vary according to the algorithm being used\n",
    "# To fix it, we can check if clf == clf1, train on different data\n",
    "    scores = cross_val_score(clf, x_train, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Average Probabilities (Soft Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.04) [Logistic Regression]\n",
      "Accuracy: 0.95 (+/- 0.04) [Random Forest]\n",
      "Accuracy: 0.96 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.96 (+/- 0.04) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50,max_depth=4, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[1.5, 2, 1])\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, x_train, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the VotingClassifier with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9619047619047617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[1.5, 2, 1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = {'lr__C': [1.0,2,3,4,5], 'rf__max_depth': [1,2,3,4,5]}\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "\n",
    "grid = grid.fit(x_train, y_train)\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "print(means.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
